<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Vidya]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://piro56.github.io/notesite/</link><image><url>https://piro56.github.io/notesite/lib/media/favicon.png</url><title>Vidya</title><link>https://piro56.github.io/notesite/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 08 Sep 2024 17:18:59 GMT</lastBuildDate><atom:link href="https://piro56.github.io/notesite/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 08 Sep 2024 17:18:57 GMT</pubDate><copyright><![CDATA[Meet Patel]]></copyright><ttl>60</ttl><dc:creator>Meet Patel</dc:creator><item><title><![CDATA[First must live the Bhagavad Gita]]></title><description><![CDATA[ 
 <br><br>Shrimad Bhagavatam: Supreme Science of the Supreme Person<br>First Canto: Gives clear explanation of the Bhagavatam.<br>
<br>Gives essence of the Vedas for devotees. 
<br>Helps further devotion
<br>Chanting helps
<br>Do not skip anything
<br>Gradually elevates reader to understand teachings in succession
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Bhagvatam/Before You Read.html</link><guid isPermaLink="false">Learning/Books/Bhagvatam/Before You Read.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[Janamejaya's Snake Sacrifice]]></title><description><![CDATA[ 
 <br><br>
<br>Mahabharata is recited at Janamejaya's snake-sacrifice
<br>Janamejaya is son of Parikshit, the snake sacrifice was organized due to Parikshit's death.
<br><br>Ugrashrava - Son of Lomaharshana<br>
<br>Also known as Souti
<br>Samantapanchaka - Land where war was fought between Kurus and Pandavas<br>"‘Duryodhana is a great tree created out of passion, Karna is its trunk, Shakuni is its branches, Duhshashana is the plentiful fruit and ﬂowers and the mindless Dhritarashtra is its root. <br>Yudhishthira is a great tree created out of righteousness, Arjuna is its trunk, Bhima is its branches, the two sons of Madri are its plentiful fruit and ﬂowers, and Krishna, Brahma and the Brahmanas are the root.]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 1.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Section 1.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 05:07:22 GMT</pubDate></item><item><title><![CDATA[Section 2 Parvasamgraha Parva]]></title><description><![CDATA[ 
 <br>
<br>Possible later addition.
<br>Summarizes the Mahabharata
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 2 Parvasamgraha Parva.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Section 2 Parvasamgraha Parva.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 22:44:48 GMT</pubDate></item><item><title><![CDATA[Section 3 Poushya Parva]]></title><description><![CDATA[ 
 <br>The story of Poushya -- sets up the Snake Sacrifice.<br>Preceptor Ayoda Dhoumya and his disciples<br>
<br>The fat disciple which ate alms, begged for alms twice -- the second time to eat from and the first to offer to his preceptor, and drank cows milk -- eventually in the end going blind and falling into a well. He then got cake from the twin gods and insisted in offering it to his preceptor, thus showing his dedication.
<br>Utanka - Disciple of Ayoda Dhoumya, who finished his time and was ready to go into householder life.<br>
<br>Example of ablution (cleaning): He ﬁrst washed his hands, face and feet properly. Then, silently, he thrice sipped just enough water, free from scum and froth, to reach his heart. He then washed twice and cleaned his oriﬁces with water.
<br>Had to get earrings from the queen for the preceptor's wife.
<br>Utanka was successful, though the earrings falling into the hands of the serpents and needing to be retrieved.
<br>Utanka then completed his duty to his preceptor and then set out for Takshaka, a serpent, and thus, we lead into Janamejaya (son of Parikshit) and the snake sacrifice.
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 3 Poushya Parva.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Section 3 Poushya Parva.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sun, 08 Sep 2024 04:12:00 GMT</pubDate></item><item><title><![CDATA[Section 4 Pouloma Parva]]></title><description><![CDATA[ 
 <br>Ugrashrava Souti was learned in the ancient tales and recounted them to Shounaka, a Brahmana. Shounaka wished to learn about the Bhrigu lineage.<br>The story of Bhrigu and his descendents.<br>
<br>Bhrigu had a son named Chyavana from his wife Puloma.
<br>A rakshasa wanted to carry Puloma away out of lust and desire, so he pleaded to agni to tell him who Puloma's husband was. Bhrigu was not there at this time. The rakshasa turned into a boar and carried Puloma away, but Chyavana in the womb fell and from his power the rakshasa was burnt to ashes.
<br>Bhrigu became angry knowing that Agni revealed Puloma to the rakshasa.
<br>Agni was cursed to be a omnivore.
<br>Agni felt the curse was unfair, and thus all sacrificial fires burnt out. 
<br>Agni was convinced by Brahma to once return, and that all burnt in Agni's flames will be pure.
<br>The story of Ruru<br>
<br>Menaka a apsara had a daughter with the king of the gandharvas Vishvavasu.
<br>The daughter given was left on the banks the river near Sthulakesha's hermitage.
<br>The sage named her Pramadvara from her immense qualities and Ruru found her and fell in love.
<br>Pramadvara died after being bitten by a snake.
<br>Ruru sacrificed half of his life for Pramadvara to come back to life (with half of Ruru's lifespan). 
<br>Ruru then killed all snakes he saw until he saw a dundubhas, a snake that is not poisonous, which then convinced him to not kill him.
<br>The dundubha then told Ruru that righteousness was non-violence and not destroying life. Therefore a Brahmana must never take the life of any living creature.
<br><br>
<br>What does Agni's curse of being a omnivore mean?

<br>Brgu cursed Agni and said he would be an 'omnivore', and would consume everything, pure and impure, indiscriminately.


]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 4 Pouloma Parva.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Section 4 Pouloma Parva.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sun, 08 Sep 2024 05:00:58 GMT</pubDate></item><item><title><![CDATA[Section 5 Astika Parva]]></title><description><![CDATA[ 
 ]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 5 Astika Parva.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Section 5 Astika Parva.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sun, 08 Sep 2024 04:55:43 GMT</pubDate></item><item><title><![CDATA[Wisdom]]></title><description><![CDATA[ 
 <br><br>Time brings existence and non-existence, pleasure and pain. Time creates all elements and time destroys all beings. Time burns all subjects and it is time that extinguishes the ﬁre. Time alone is awake when everything is asleep. Time cannot be conquered. Time walks in all elements, pervasive and impartial. Knowing that everything, past, present and future, is created by time<br>
<br>Page 32
<br>Asceticism is not a sin, studying is not a sin, the natural rules of the Vedas are not sins and exertion to acquire wealth is not a sin. These become sins when they are abused.’<br>
<br>Page 33
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Wisdom.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Volume 1/Wisdom.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 21:00:49 GMT</pubDate></item><item><title><![CDATA[Mahabharata]]></title><description><![CDATA[ 
 <br><br>
<br>Volume 1

<br><a data-href="Section 1" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 1.html" class="internal-link" target="_self" rel="noopener">Section 1</a>
<br><a data-href="Section 2 Parvasamgraha Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 2 Parvasamgraha Parva.html" class="internal-link" target="_self" rel="noopener">Section 2 Parvasamgraha Parva</a>
<br><a data-href="Section 3 Poushya Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 3 Poushya Parva.html" class="internal-link" target="_self" rel="noopener">Section 3 Poushya Parva</a>
<br><a data-href="Section 4 Pouloma Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 4 Pouloma Parva.html" class="internal-link" target="_self" rel="noopener">Section 4 Pouloma Parva</a>
<br><a data-href="Section 5 Astika Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 5 Astika Parva.html" class="internal-link" target="_self" rel="noopener">Section 5 Astika Parva</a>
<br><a data-href="Wisdom" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Wisdom.html" class="internal-link" target="_self" rel="noopener">Wisdom</a>


<br><br>
<br>Ending Page: 34
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Mahabharata/Mahabharata.html</link><guid isPermaLink="false">Learning/Books/Mahabharata/Mahabharata.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sun, 08 Sep 2024 04:55:52 GMT</pubDate></item><item><title><![CDATA[Authors]]></title><description><![CDATA[ 
 <br>
<br>Candrakirti
<br>Nagarjuna
<br>Sankaracharya
<br>Vivekananda
]]></description><link>https://piro56.github.io/notesite/Learning/Books/Authors.html</link><guid isPermaLink="false">Learning/Books/Authors.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[List]]></title><description><![CDATA[ 
 <br>
<br>&nbsp;Nāgārjuna's Madhyamaka: A Philosophical Introduction Jan Westeroff
<br>Tattvabodha - Adi Sankaracharya
<br>Problem of Evil in Indian Thought - Professor Arthur Herman
<br>Bhagvatam
<br>Satsangi Jivan
]]></description><link>https://piro56.github.io/notesite/Learning/Books/List.html</link><guid isPermaLink="false">Learning/Books/List.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[1 Vectors]]></title><description><![CDATA[ 
 <br>Scalars - Single numbers -- constants.<br><br><br>Vector is a line -- [1 2], a line with slope 2.<br><br><br><br>Convention to assume vectors are in column orientation, unless stated otherwise!<br><br><br><br>Should be trivial.<br><br>Also known as the inner product or scalar product.<br>
Important because it provides information about the relationship between two vectors.<br>
Is applied in:<br>
<br>Convolution
<br>Correlation
<br>Fourier Transform
<br>Matrix Multiplication
<br>Signal Filtering
<br><br><br>Example: <br><br>Taking the dot product on vector itself:<br><br><br><br>Scalar:                       (c is a constant)<br>
However, this does not apply with dot products:<br>
Row vs. Column Vector Output: <br><br><br><br>Interesting Example:<br>
<br><br><br><br><br> = Angle between two vectors<br>
Can rewrite the equation:<br>

<br><br>Sign is determined exclusively by angle (the magnitudes are lengths and thus always positive) 
1 Cosine of acute angle is always positive<br>
2 Cosine of obtuse angle is always negative<br>
3 Cosine of right angle is 0, vectors are orthogonal<br>
4 Cosine of 0 is 1. The lines are collinear (or the same line).<br>
5 Same as 4, but with negative sign. Still referred to as collinear<br>

<br><br>Equivalence
 
<br>Proof
Check page 53 of Cohen, to prove:<br>

<br><br>

<br>
<br>All vectors have the same dimensionality
<br> can be any real number including 0.
<br><br>Way of combining two vectors to produce a matrix.
 and  are column vectors.<br>

<br><br>Each element  in the outer product matrix is the scalar multiplication between  element in first vector and  element in second.<br> <br><br><br>Each column in the outer product matrix comes from repeating the left vector but scaled by each element in the row vector<br><br>Form outer product matrix one row at a time, by repeating row vector M times (for M elements of vector w).<br><br>Multiply corresponding elements in the two vectors. Requires same number of elements.<br>
<br><br>Only defined for 3-element vectors, and results in another 3-element vector.<br>Geometry based formula, used to create a vector c which is orthogonal to the plane spanned by vectors  and . <br><br>Vector with length of one: <br>
 ]]></description><link>https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/1 Vectors.html</link><guid isPermaLink="false">Learning/Math/Linear Algebra/Theory, Intuition, Code/1 Vectors.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[2 Vector Spaces]]></title><description><![CDATA[ 
 <br><br><br>Simply the number of elements in the vector. Order is important, but no dimension is more important than another,<br><br>Dimensionality of a vector is number of coordinate axes the vector exists.<br>
For example 2D vector is in 2D space.<br>Major departure from typical Cartesian axis:<br>
<br>Coordinates do not need to be orthogonal (ex. x and y dimensions are orthogonal from one another)
<br>Can have non-orthogonal axis.
<br><br>Field - A set of numbers for which basic arithmetic operations are defined.<br>
<br> - Real Numbers 
<br> - Complex Numbers
<br> - Rational Numbers
<br>For example  stands for all real 2-dimensional numbers.<br><br>Vector Space - Any set of objects for which addition and scalar multiplication are defined.<br>Required Properties (addition and scalar multiplication):<br>
<br>Additive Inverse: 
<br>Associativity: 
<br>Commutativity: 
<br>Additive Identity: 
<br>Multiplicative Identity: 
<br>Distributivity: 
<br><br><br>Subspace - is the set of all points you can reach by stretching and combining a collection of vectors (i.e. by addition and scalar multiplication)<br>With one 2-D vector, we can create a infinitely long line.<br>
With two 2-D vectors, we can potentially reach many points -- to which we can span a plane.<br><br>Distinction between subspace and ambient space: subspace is embedded.<br>
For example, a subspace of 2D can be embedded in a 3D ambient space.<br>Dimensionalities vs. Subspaces
How many subspaces are possible in a ambient space?<br>
Infinitely Many<br>
How many subspace dimensionalities are possible with a N-dim ambient space?<br>
Finite Number: N+1
<br>For example, for , there are  subspace dimensionalities. .<br><br>Subspace - is the set of all points that satisfies:

<br>Closed under addition and scalar multiplication
<br>Contains zeros vector 0





<br>1D subspace embedded in a a 3D ambient space

<br><br>Subset - Region in space that can have boundaries instead of extending to infinity

<br>Set of all points on XY plane s.t.  and 
<br>Set of all points s.t.  and 
<br>Set of all points s.t.  (this is also a subspace)

<br><br><br>Similar to subspace, but span is the region of ambient space that can be reached by any linear combination of a set of vectors.<br>
Can be thought of as:<br>
<br>Subspace is a noun
<br>Span is a verb<br>
A set of vectors span, and the result is a subspace.
<br><br>Span is set of all points that can be obtained by any linear weighted combination of those vectors

<br><br><br>Set of vectors is independent iff the dimensionality of the subspace spanned is equal to the number of vectors in the set.

<br>A linearly independent set of 2 vectors spans a plane (2D)
<br>A linearly independent set of 3 vectors, spans a 3D space.

<br>Note, have 2 vectors in a set does not necessarily endow that set with linear independence.<br>
<br>For example, having 2 collinear vectors is not linear independence since they span a 1D space.

<br>: Does not span 2d space, since collinear.


<br>Having 3 vectors in  does not imply independence, since they can only span 2D space, not 3D.

<br>:  can be obtained from adding , also obvious we can only span 2D space.


<br>Theorem

<br>Any set of  vectors in  is necessarily linearly dependent.
<br>Any set of  vectors in  is possibly linearly independent.

<br><br>A set of vectors is dependent if at least one vector can be expressed as a linear weighted combination of the other vectors in that set
Dependent Set: 
<br>Example of dependent set. We can see  can be created from <br>
<br>Any vector with the zeros vector is dependent.<br>Determining whether a set is linearly dependent or independent<br>
<br>Count number of vectors, using theorem, if  then it is necessarily dependent, else, you move to step 2
<br>Check for zeros vector
<br>Do guessing by looking for zeros in entries and taking advantage that nothing can be created with zeros.
<br>Educated guessing: try creating a weighted combination of one element using combination of other vectors.
<br><br>Basis is the combination if span and independence
A set of vectors  forms a basis for some subspace of  IF it both:

<br>Spans that subspace
<br>Is an independent set of vectors

<br>Cartesian Axis Basis Vectors
  
<br>It is not necessary for a basis to span all of , you can have basis sets for subspaces embedded in 

<br>Geometric Tip: A basis should provide a unique way to obtain a pair of coordinates (think cartesian basis which can directly correspond to x,y,z). If a basis set were not linearly independent, then we would not have a unique way to obtain all coordinates -- some coordinates could be produced in infinitely many ways.]]></description><link>https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/2 Vector Spaces.html</link><guid isPermaLink="false">Learning/Math/Linear Algebra/Theory, Intuition, Code/2 Vector Spaces.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[3 Matrices]]></title><description><![CDATA[ 
 <br>Rows and Columns<br>
Matrix Related Terms:<br>
<br>Row, Column
<br>Element
<br>Block
<br>Diagonal
<br>Skew-Diagonal
<br>Off-Diagonal
<br>Block Matrix: A matrix that is composed of smaller matrices<br>MR NiCe, M = Row, N = Column in a  matrix<br><br>Dimensionality is flexible and versatile. Matrices can have different interpretations of dimensionality based on application.<br>
<br>
<br> - If each matrix element is it's own dimension
<br> - If matrix is a series of column vectors
<br> - If matrix is a series of row vectors
<br><br>Swap rows for columns and vice versa


<br><br>Non-exhaustive categorization of some special matrices.<br><br>Square:  matrix.<br>
Rectangular: <br><br>A matrix is symmetric if it is "mirrored" across the diagonal.<br>Formally a matrix is symmetric if it equals it's transpose.


<br>Symmetric matrices have many useful  properties.<br><br>Skew-Symmetric: Where the lower-triangle is the sign flipped version of the upper triangle.


<br>Diagonals must be zero for skew-symmetric . <br><br>Matrix equivalent to the number "1"<br>Identity
Has 's on the diagonals.<br>

<br>Although known as the identity matrix, it is more accurately the: multiplicative identity matrix
For addition, the identity matrix is the zeros matrix.
<br><br>Matrix of all zeros. Is the identity matrix for addition.<br>
<br>
<br><br> is one of the most important matrix forms in linear algebra.
Key properties of  (also ):

<br>Is a square matrix even if  is rectangular.
<br>Symmetric even if  isn't.
<br>Full-rank if  is full column-rank.
<br>Invertible if  is full column-rank
<br>Same row space as 
<br>Has orthogonal eigenvectors
<br>Positive (semi)definite
<br>Has non-negative, real-valued eigenvalues
<br>Is called a "covariance matrix" if  is a data mtrix
<br>Looks pretty?

<br><br>All zeros on off-diagonals.<br>If all diagonals are the same:

<br>Diagonal matrices can be rectangular.

<br><br>The result of concatenating two or more matrices column wise.<br><br><br>Halfway between diagonal and  full matrix.<br>
Upper Triangular: Only diagonal and above have elements<br>
Lower Triangular:** Only diagonal and below have elements<br><br>Dense: A matrix where most elements are non-zero.<br>
Sparse: A matrix where most elements are zero.<br><br>Orthogonal Criteria

<br>All of it's columns are pairwise orthogonal. Dot product between any two columns is 0.
<br>Unit Magnitude: each column  has , 

<br><br>Diagonals have the same element

<br><br>Similar to a rotated Toeplitz

<br>Creating a Hankel matrix from a vector

<br><br><br>Pretty simple.<br>
Commutative: <br><br><br><br>Shifting and Properties


<br>Only diagonal elements get changed.
<br>Shifting can make matrices with redundant rows (or columns), distinct.
<br>When  is close to zero, then  is similar to .

<br><br>Get the diagonal vector from a matrix.<br><br>Sum of diagonal elements.<br>Trace is only defined for square matrices]]></description><link>https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/3 Matrices.html</link><guid isPermaLink="false">Learning/Math/Linear Algebra/Theory, Intuition, Code/3 Matrices.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[4 Matrix Multiplication]]></title><description><![CDATA[ 
 <br>ro
Copy<br><br>Not Commutative: <br>
<br>There are exceptions: 
<br><br>Validity
Inner dimensions must match. Outer dimensions are the size of the resultant matrix.<br>

<br><br><br>Each element  in  is the dot product between the  row in  and the  column in 

<br><br>
<br>The diagonal of the product matrix  contains dot products between rows and columns of the same ordinal position (row  in  and column  in )
<br>The lower-triangle of C contains dot products between later rows in  and earlier columns in 
<br>The upper-triangle of C contains dot products between earlier rows in A and later columns in B
<br><br>In contrast to the element perspective, the layer perspective conceptualizes the product matrix as a series of layers or "sheets", that are summed together.<br>
<br>Implemented by creating outer products from the columns of  and the rows of , then summing them together.
<br>Each outer product is the same size as  and can be thought of as a layer.
<br><br>Columns in layers form a dependent set (same for rows)
Sum of the singular matrices (the product matrix) has columns that form a linearly independent set. 

<br>Closely related to the spectral theorem of matrices

<br><br>All matrices are thought of as sets of column vectors, and the product matrix is created one column at a time.<br>First column in the product matrix is a linear weighted combination of all columns in the left matrix, where weights are defined by the elements in the first column of the right matrix.<br>
Second column is again a weighted combination of all columns in the left matrix, except now weights come from the second column in the right matrix, and so on for rest of the N columns.<br><br>
<br>Useful in statistics when left matrix is a set of regressors, and the right matrix contains coefficients.
<br><br>Same as column perspective but build up 1 row at a time.<br>
Take weighted combination of rows to build product matrix.<br><br>Important note on matrix multiplication ordering<br>
<br><br>
<br>Pre-Multiplication by a diagonal matrix scales the rows of the right matrix by the diagonal elements.
<br>Post-Multiplication by a diagonal matrix scales the columns of the left matrix by the diagonal elements
<br>Examples<br>
Pre:<br><br>Post:<br><br><br>Multiplying 2 diagonal matrices is just multiplying together diagonal elements<br><br><br>
Operation on multiplied matrices gets applied to each in reverse order.<br>
Therefore, Live Evil (palindrome)
<br><br>Same thing as normal matrix multiplication, think of vector as Mx1 or 1xN matrix.<br>
3 Observations:<br>
<br> is not defined (assuming b is a column vector)
<br>If  is rectangular, then either  or  is undefined.
<br> even when both are valid operations.
<br>Symmetric matrix times a vector

<br><br><br><br>
<br>Works only for square matrices.
<br> is for normalization.
<br><br><br><br>Generally the result is not symmetric<br><br>Multiply the element at  with <br>
<br>Requires matrices of same size.
<br>Results in matrix of same size
<br><br>
<br>Vectorize the two matrices
<br>Compute their dot product
<br>Result: A single number
<br>Vectorizing: Concatenate all of the columns to produce a single column vector.<br>
<br>Can also concatonate all of the rows to produce a single row vector.
Alternative way to calculate Frobenius using trace



<br><br>A single number that corresponds to the "magnitude" of a matrix. <br>
<br>Different norms correspond to different notions of "magnitude".
<br>If we think of the matrix space as Euclidean then Frobenius norm can be used to measure euclidean distance between two matrices.<br>
<br>Matrix p-norm


<br>Same as Frobenius norm if p=2

<br><br>]]></description><link>https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/4 Matrix Multiplication.html</link><guid isPermaLink="false">Learning/Math/Linear Algebra/Theory, Intuition, Code/4 Matrix Multiplication.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[5 Rank]]></title><description><![CDATA[ 
 <br>
<br>Rank is indicated by letter  or , and is a non-negative integer.
<br>Maximum possible rank is  for MxN matrix.
<br>Rank is a property of the entire matrix (not just columns or rows).
<br>Rank Terminology

<br> Full Rank
<br> Full Column rank 
<br> Full Row rank
<br> "Reduced Rank"


<br>Rank indicates number of dimensions of  contained in the matrix.
<br>Rank is the largest number of columns/rows that can form a linearly independent set
<br>Why is rank important?
Some operations in linear algebra only apply to full-rank matrices (such as inversion).<br>
Some operations only work on reduced-rank matrices (eigendecomposition).<br>
Additionally, many computer algorithms return more reliable results using full-rank matrices. Regularization in statistics and machine learning is to increase numerical stability by ensuring data matrices are full rank.
<br><br>If you think of a matrix as a set of vectors, then rank is the largest number of vectors that can form a linearly independent set.<br><br>Rank is the dimensionality of the subspace spanned by the columns or rows of the matrix.<br>
Consider above, this vector is in . but only spans a 1D subspace.<br>
<br>All vectors have a rank of 1 except zeros vector with a rank of 0.
<br>Consider 2 vectors:<br>
 The rank is 2 if we view it by either column or row perspective. (Either 3 2D vectors, or 2 3D).<br><br>3 Ways:<br>
<br>Count largest number of columns or rows that can form a linearly independent set.
<br>Count the number of pivots in the echelon or row-reduced echelon form of the matrix.
<br>Count the number of nonzero singular values from a singular value decomposition of the matrix.
<br>]]></description><link>https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/5 Rank.html</link><guid isPermaLink="false">Learning/Math/Linear Algebra/Theory, Intuition, Code/5 Rank.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[Math]]></title><description><![CDATA[ 
 <br><br>
<br>Linear Algebra

<br>Theory, Intuition, Code

<br><a data-href="1 Vectors" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/1 Vectors.html" class="internal-link" target="_self" rel="noopener">1 Vectors</a>
<br><a data-href="2 Vector Spaces" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/2 Vector Spaces.html" class="internal-link" target="_self" rel="noopener">2 Vector Spaces</a>
<br><a data-href="3 Matrices" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/3 Matrices.html" class="internal-link" target="_self" rel="noopener">3 Matrices</a>
<br><a data-href="4 Matrix Multiplication" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/4 Matrix Multiplication.html" class="internal-link" target="_self" rel="noopener">4 Matrix Multiplication</a>
<br><a data-href="5 Rank" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/5 Rank.html" class="internal-link" target="_self" rel="noopener">5 Rank</a>




<br>]]></description><link>https://piro56.github.io/notesite/Learning/Math/Math.html</link><guid isPermaLink="false">Learning/Math/Math.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[Learning]]></title><description><![CDATA[ 
 <br><br>
<br>Books

<br><a data-href="Authors" href="https://piro56.github.io/notesite/Learning/Books/Authors.html" class="internal-link" target="_self" rel="noopener">Authors</a>
<br>Bhagvatam

<br><a data-href="Before You Read" href="https://piro56.github.io/notesite/Learning/Books/Bhagvatam/Before You Read.html" class="internal-link" target="_self" rel="noopener">Before You Read</a>


<br><a data-href="List" href="https://piro56.github.io/notesite/Learning/Books/List.html" class="internal-link" target="_self" rel="noopener">List</a>
<br><a data-href="Mahabharata" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Mahabharata.html" class="internal-link" target="_self" rel="noopener">Mahabharata</a>

<br>Volume 1

<br><a data-href="Section 1" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 1.html" class="internal-link" target="_self" rel="noopener">Section 1</a>
<br><a data-href="Section 2 Parvasamgraha Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 2 Parvasamgraha Parva.html" class="internal-link" target="_self" rel="noopener">Section 2 Parvasamgraha Parva</a>
<br><a data-href="Section 3 Poushya Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 3 Poushya Parva.html" class="internal-link" target="_self" rel="noopener">Section 3 Poushya Parva</a>
<br><a data-href="Section 4 Pouloma Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 4 Pouloma Parva.html" class="internal-link" target="_self" rel="noopener">Section 4 Pouloma Parva</a>
<br><a data-href="Section 5 Astika Parva" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Section 5 Astika Parva.html" class="internal-link" target="_self" rel="noopener">Section 5 Astika Parva</a>
<br><a data-href="Wisdom" href="https://piro56.github.io/notesite/Learning/Books/Mahabharata/Volume 1/Wisdom.html" class="internal-link" target="_self" rel="noopener">Wisdom</a>






<br><a data-href="Math" href="https://piro56.github.io/notesite/Learning/Math/Math.html" class="internal-link" target="_self" rel="noopener">Math</a>

<br>Linear Algebra

<br>Theory, Intuition, Code

<br><a data-href="1 Vectors" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/1 Vectors.html" class="internal-link" target="_self" rel="noopener">1 Vectors</a>
<br><a data-href="2 Vector Spaces" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/2 Vector Spaces.html" class="internal-link" target="_self" rel="noopener">2 Vector Spaces</a>
<br><a data-href="3 Matrices" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/3 Matrices.html" class="internal-link" target="_self" rel="noopener">3 Matrices</a>
<br><a data-href="4 Matrix Multiplication" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/4 Matrix Multiplication.html" class="internal-link" target="_self" rel="noopener">4 Matrix Multiplication</a>
<br><a data-href="5 Rank" href="https://piro56.github.io/notesite/Learning/Math/Linear Algebra/Theory, Intuition, Code/5 Rank.html" class="internal-link" target="_self" rel="noopener">5 Rank</a>






<br>]]></description><link>https://piro56.github.io/notesite/Learning/Learning.html</link><guid isPermaLink="false">Learning/Learning.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sun, 08 Sep 2024 04:55:52 GMT</pubDate></item><item><title><![CDATA[Callouts]]></title><description><![CDATA[ 
 <br>
Callout: "&gt; anything"
<br>done, success, check<br>Tips: tip, hint, important<br>!note<br>example<br>quote, cite<br>[!question]<br> FAQ: [!faq]<br>warning, attention, caution<br>fail, failure, missing<br>danger, error<br>bug]]></description><link>https://piro56.github.io/notesite/Obsidian/Examples/Callouts.html</link><guid isPermaLink="false">Obsidian/Examples/Callouts.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[Obsidian]]></title><description><![CDATA[ 
 <br><br>
<br>Examples

<br><a data-href="Callouts" href="https://piro56.github.io/notesite/Obsidian/Examples/Callouts.html" class="internal-link" target="_self" rel="noopener">Callouts</a>


<br>Templates
<br><br><br>"%% Waypoint %%"<br><br>
---<br>
tags:<br>
 tag<br>
 you're it<br>
---
<br><br><a rel="noopener" class="external-link" href="https://docs.obsidianweb.net/" target="_blank">https://docs.obsidianweb.net/</a>]]></description><link>https://piro56.github.io/notesite/Obsidian/Obsidian.html</link><guid isPermaLink="false">Obsidian/Obsidian.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[Index]]></title><description><![CDATA[ 
 <br><a data-href="Learning" href="https://piro56.github.io/notesite/Learning/Learning.html" class="internal-link" target="_self" rel="noopener">Learning</a>]]></description><link>https://piro56.github.io/notesite/Index.html</link><guid isPermaLink="false">Index.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item><item><title><![CDATA[preamble]]></title><description><![CDATA[ 
 <br> <br>
 <br>
 ]]></description><link>https://piro56.github.io/notesite/preamble.html</link><guid isPermaLink="false">preamble.md</guid><dc:creator><![CDATA[Meet Patel]]></dc:creator><pubDate>Sat, 07 Sep 2024 03:46:30 GMT</pubDate></item></channel></rss>